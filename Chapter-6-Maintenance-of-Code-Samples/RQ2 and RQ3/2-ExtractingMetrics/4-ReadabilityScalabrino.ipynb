{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install GitPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStatus(index, size):\n",
    "    print(\"{0}% Completed samples\".format((index / size) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "from statistics import mean\n",
    "import shutil\n",
    "import git\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To run this code you need to download the 'rsm.jar' found in 'https://dibt.unimol.it/report/readability/', and it should be stored at root path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReadability(file):\n",
    "    file = file.replace(\"/\", \"\\\\\")\n",
    "    r = os.popen(f\"java -jar rsm.jar {file}\").read().replace(\"\\n\", \"\")   \n",
    "    try:\n",
    "        readability = float(r.split(\"\\t\")[-1])\n",
    "        if math.isnan(readability):\n",
    "            return 0\n",
    "        else:\n",
    "            return readability\n",
    "    except:\n",
    "        print(r)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv(\"../1-GettingQuestions/sampleQuestions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = samples[samples[\"framework\"] == \"SAP-samples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[\"full_name\"] = samples[\"framework\"] + \"/\" + samples[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples[\"full_name\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = samples[samples.index(\"googlesamples/android-testdpc\")+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    print(sample)\n",
    "    \n",
    "    file_address = f\"metrics/{sample}.csv\"\n",
    "    metrics = pd.read_csv(file_address)\n",
    "    metrics[\"Scalabrino Readability\"] = 0\n",
    "\n",
    "    last_commit_result = (\"0\",0)\n",
    "    printStatus(samples.index(sample), len(samples))\n",
    "    \n",
    "    arquivos = dict()\n",
    "    \n",
    "    for index in range(0, len(metrics)):\n",
    "        print(f\"{index}/{len(metrics)} of line analized from {sample}\")\n",
    "        print(\"inicio análise da linha \" + str(index))\n",
    "        inicio = datetime.datetime.now()\n",
    "\n",
    "\n",
    "        current_commit = metrics.iloc[index][\"commitSha\"]\n",
    "        \n",
    "#         print(\"Checking if is the same commit\")\n",
    "        if current_commit == last_commit_result[0]:\n",
    "            metrics.iloc[index, len(metrics.columns.values) - 1] = last_commit_result[1]\n",
    "            metrics.to_csv(file_address, index=False)\n",
    "#             print(\"Fim análise porque é o mesmo commit\")\n",
    "            continue\n",
    "        \n",
    "        repository = Repo(\"repositories/\"+sample)\n",
    "\n",
    "        java_files = list()\n",
    "        for file in repository.commit(current_commit).stats.files:\n",
    "            if \"java\" in file.split(\".\"):\n",
    "                java_files.append(file)\n",
    "\n",
    "\n",
    "        if not len(java_files):\n",
    "            metrics.iloc[index, len(metrics.columns.values) - 1] = last_commit_result[1]\n",
    "            metrics.to_csv(file_address, index=False)\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            repository.git.checkout(current_commit, \"-f\")\n",
    "            print(f\"{len(java_files)} files to be analyzed\")\n",
    "            for file in java_files:\n",
    "                if(\"java\" in file.split(\".\")):\n",
    "                    readability = getReadability(f\"repositories/{sample}/{file}\")\n",
    "                    arquivos[file] = readability\n",
    "                    \n",
    "            last_commit_result = (current_commit, mean(list(arquivos.values())) )\n",
    "\n",
    "            metrics.iloc[index, len(metrics.columns.values) - 1] = last_commit_result[1]\n",
    "            metrics.to_csv(file_address, index=False)\n",
    "            print(\"Fim análise com a execução da readability\")\n",
    "            fim = datetime.datetime.now()\n",
    "            print(\"Tempo gasto: \" + str((fim - inicio).total_seconds()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
